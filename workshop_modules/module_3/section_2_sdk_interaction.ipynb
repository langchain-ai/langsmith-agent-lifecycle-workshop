{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 3, Section 2: Interacting with Deployments via SDK\n",
        "\n",
        "Our agent is now deployed to production with monitoring in place. But how do we actually **use** it?\n",
        "\n",
        "In this section, we'll learn how to interact with our deployed agent programmatically using the **LangGraph SDK**. This enables you to:\n",
        "- Build custom UIs and applications\n",
        "- Automate testing and workflows\n",
        "- Handle human-in-the-loop interrupts\n",
        "- Integrate with existing systems\n",
        "\n",
        "By the end, you'll be able to call your deployed agent from any Python application.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "from langgraph_sdk import get_client\n",
        "from langgraph_sdk.schema import Command\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Connect to your deployment\n",
        "DEPLOYMENT_API_URL = \"your-deployment-api-url\"\n",
        "client = get_client(url=DEPLOYMENT_API_URL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 1. Basic Invocation\n",
        "\n",
        "Let's start simple - call our deployed agent and get a response.\n",
        "\n",
        "We'll ask about product information (no identity verification needed).\n",
        "\n",
        "\n",
        "**Note:** First invocation to subagent that uses vector search will build the vector DB on-demand, one time setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent: Based on our product documentation, here are the **key features of the Sony WH-1000XM5 headphones**:\n",
            "\n",
            "**Noise Cancellation:**\n",
            "- Industry-leading Active Noise Cancellation (ANC) with 8 microphones\n",
            "- HD Noise Cancelling Processor QN1 that adjusts 700 times per second\n",
            "- Excellent at blocking low-frequency noise (planes, traffic) and mid-frequency sounds (conversations, office noise)\n",
            "- NC Optimizer feature personalizes cancellation to your ear shape and fit\n",
            "\n",
            "**Audio Quality:**\n",
            "- Premium 30mm drivers delivering rich, detailed sound\n",
            "- Compatible with all Bluetooth devices (iOS, Android, Windows, Mac)\n",
            "\n",
            "**Battery & Connectivity:**\n",
            "- **30-hour battery life** (exceptional for wireless headphones)\n",
            "- Seamless multi-device connectivity\n",
            "\n",
            "**Microphone & Call Quality:**\n",
            "- 4 beamforming microphones for clear call quality\n",
            "- 4 ANC microphones\n",
            "\n",
            "**Smart Controls:**\n",
            "- Touch-sensitive controls on the right earcup: tap to play/pause, double-tap to skip, swipe for volume\n",
            "- Quick Attention mode to temporarily lower volume by covering the earcup\n",
            "- Sony Headphones Connect app for EQ customization, ANC adjustments, and updates\n",
            "\n",
            "**Design:**\n",
            "- Built for all-day comfort\n",
            "- Perfect for travelers, professionals, and music enthusiasts\n",
            "\n",
            "Would you like information about pricing, availability, or anything else about these headphones?\n"
          ]
        }
      ],
      "source": [
        "# Create a thread (conversation session)\n",
        "thread = await client.threads.create()\n",
        "\n",
        "# Send a message\n",
        "input_message = {\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What are the key features of the Sony WH-1000XM5 headphones?\",\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Invoke the agent (wait for completion)\n",
        "response = await client.runs.wait(\n",
        "    thread[\"thread_id\"],\n",
        "    \"supervisor_hitl_sql_agent\",  # Your deployed graph name\n",
        "    input=input_message,\n",
        ")\n",
        "\n",
        "# Print the final response\n",
        "final_message = response[\"messages\"][-1][\"content\"]\n",
        "print(f\"Agent: {final_message}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What just happened?**\n",
        "1. Created a new thread (like starting a new conversation)\n",
        "2. Sent a message to the agent\n",
        "3. Waited for the agent to complete\n",
        "4. Retrieved the final message\n",
        "\n",
        "**Note:** Check LangSmith - you'll see this trace in your `langsmith-agent-lifecycle-workshop-deployment` project!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. Human-in-the-Loop (HITL) with SDK\n",
        "\n",
        "Our agent requires email verification for personal account questions. Let's see how to handle **interrupts** programmatically.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Start a Conversation That Requires Verification\n",
        "\n",
        "**Note:** LangSmith Studio automatically handles interrupt resumption in its UI, but when using the SDK programmatically, you need to explicitly use the `Command(resume=...)` pattern (see Step 3).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'id': '23754cfd4d40de50b188c85d3bbd4cee', 'value': 'Please provide your email:'}]\n"
          ]
        }
      ],
      "source": [
        "# Create a new thread\n",
        "thread = await client.threads.create()\n",
        "thread_id = thread[\"thread_id\"]\n",
        "\n",
        "# Ask about order status (requires email verification)\n",
        "input_message = {\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"What's the status of my recent order?\"}]\n",
        "}\n",
        "\n",
        "# Run the graph until the interrupt is hit\n",
        "result = await client.runs.wait(\n",
        "    thread_id,\n",
        "    \"supervisor_hitl_sql_agent\",\n",
        "    input=input_message,\n",
        ")\n",
        "\n",
        "# Print the interrupt\n",
        "print(result[\"__interrupt__\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Check the Interrupt and Get State\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent says: To access information about your account or orders, please provide your email address.\n"
          ]
        }
      ],
      "source": [
        "# Get the current state\n",
        "state = await client.threads.get_state(thread_id)\n",
        "\n",
        "# The agent is waiting for email input\n",
        "# Check the last message\n",
        "last_message = state[\"values\"][\"messages\"][-1][\"content\"]\n",
        "print(f\"Agent says: {last_message}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Provide Email and Resume\n",
        "\n",
        "**Important:** To resume an interrupted run:\n",
        "1. Call `client.runs.wait()` again on the **same thread**\n",
        "2. Pass `command=Command(resume=...)` with the user's input (as a string)\n",
        "3. The agent resumes from the interrupt point with the provided value\n",
        "\n",
        "**Key:** The `Command(resume=...)` tells the SDK to resume the interrupted run rather than starting a new one. The value you pass to `resume` becomes the return value of the `interrupt()` call in your graph code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Agent: Your recent order **ORD-2025-0044** is currently in **Processing** status. Here are the details:\n",
            "\n",
            "- **Order Date:** October 15, 2025\n",
            "- **Total Amount:** $549.00\n",
            "- **Status:** Processing\n",
            "- **Shipped Date:** Not yet shipped\n",
            "- **Tracking Number:** Not yet available\n",
            "\n",
            "Your order is being prepared and will be shipped soon. Once it's dispatched, you'll receive tracking information so you can monitor its delivery progress. Is there anything else you'd like to know about this order?\n"
          ]
        }
      ],
      "source": [
        "# Resume the graph by passing the email as a Command\n",
        "# Note: We pass the user's message content directly to Command(resume=...)\n",
        "response = await client.runs.wait(\n",
        "    thread_id,\n",
        "    \"supervisor_hitl_sql_agent\",\n",
        "    command=Command(resume=\"My email is consultant.tech@gmail.com\"),\n",
        ")\n",
        "\n",
        "# Get the final answer\n",
        "final_message = response[\"messages\"][-1][\"content\"]\n",
        "print(f\"\\nAgent: {final_message}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Ask a Follow-Up (No Interrupt This Time!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent: Your order **ORD-2025-0044** contains:\n",
            "\n",
            "- **1x Dell UltraSharp 27\" 4K Monitor** - $549.00\n",
            "\n",
            "This is a high-quality 4K monitor, and it's currently in stock. Your order is being prepared for shipment. Is there anything else you'd like to know about your order or this product?\n"
          ]
        }
      ],
      "source": [
        "# Ask a follow-up question (customer_id already verified!)\n",
        "followup_message = {\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"What exactly was in that order?\"}]\n",
        "}\n",
        "\n",
        "response = await client.runs.wait(\n",
        "    thread_id,\n",
        "    \"supervisor_hitl_sql_agent\",\n",
        "    input=followup_message,\n",
        ")\n",
        "\n",
        "final_message = response[\"messages\"][-1][\"content\"]\n",
        "print(f\"Agent: {final_message}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What happened?**\n",
        "1. First question triggered email verification (interrupt)\n",
        "2. We resumed with `Command(resume=...)` to provide the email\n",
        "3. Follow-up question didn't interrupt - `customer_id` is already in thread state!\n",
        "\n",
        "**Key HITL Pattern:**\n",
        "- Use `command=Command(resume=value)` on the same thread to resume an interrupt\n",
        "- The value becomes the return value of `interrupt()` in your graph\n",
        "- Thread state (like `customer_id`) persists across runs on the same thread\n",
        "\n",
        "This is how you build custom UIs with HITL flows.\n",
        "\n",
        "**Learn more:** [HITL with SDK Docs](https://docs.langchain.com/langsmith/add-human-in-the-loop)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. Monitoring Production Traces\n",
        "\n",
        "Every SDK call creates a trace in LangSmith. Let's verify our online evaluator is working.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check LangSmith for Your Traces\n",
        "\n",
        "**Steps:**\n",
        "1. Go to **LangSmith** → **Projects** → **langsmith-agent-lifecycle-workshop-deployment**\n",
        "2. You'll see all the traces from your SDK calls\n",
        "3. Click on any trace to see:\n",
        "   - Full conversation history\n",
        "   - Tool calls and reasoning\n",
        "   - Latency metrics\n",
        "   - Any errors or warnings\n",
        "\n",
        "**After 1 minute** (your thread idle time), check the **Feedback** tab on each trace:\n",
        "- You should see `user_sentiment: positive` (since we had helpful conversations)\n",
        "- The online evaluator runs automatically!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
