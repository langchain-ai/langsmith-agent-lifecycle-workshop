{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Human-in-the-Loop with LangGraph Primitives\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"../../images/supervisor_with_verification.png\" width=\"800\">\n",
    "</div>\n",
    "\n",
    "In Section 3, we built a supervisor using `create_agent` that routes queries to specialized sub-agents.\n",
    "\n",
    "However, to handle some underspecified queries like _\"Whats the status of my recent order?\"_, we need to first verify the customer's identity **before** the agent can provide support.\n",
    "\n",
    "In this section, we'll add a **verification layer** to our agent using LangGraph primitives that:\n",
    "- Classifies whether a user question needs identity verification\n",
    "- Pauses execution to collect customer email (HITL)\n",
    "- Validates the email against our customer database to get a `customer_id`\n",
    "- Skips verification on follow-up questions in the same thread\n",
    "- Routes to our Supervisor Agent for the actual query handling\n",
    "\n",
    "We keep the sub-agents simple (`create_agent`), but add more complex orchestration with LangGraph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383f3c43",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Load environment variables and necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb878025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e854006",
   "metadata": {},
   "source": [
    "## Build Verification Layer with LangGraph Primitives\n",
    "\n",
    "Let's add the verification layer that sits **in front of** the supervisor. To do so, we'll need to:\n",
    "1. Define a custom state schema that stores a `customer_id` once the user is verified\n",
    "2. Build a set of nodes and edges that implement our verification and routing logic\n",
    "3. Compile our state + nodes + supervisor agent into a graph that we can invoke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9c9b9d",
   "metadata": {},
   "source": [
    "### State Schema\n",
    "\n",
    "Since we'll now be collecting and storing information about the customer, we need to make sure this information is persisted in our graph's state. \n",
    "\n",
    "We'll extend LangGraph's `MessagesState` to include a `customer_id`, so this value will be shared across the verification layer, supervisor, and sub-agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce78743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "\n",
    "class IntermediateState(MessagesState):\n",
    "    \"\"\"Extended MessagesState with customer_id\n",
    "\n",
    "    MessagesState includes a `messages` key with proper reducers by default.\n",
    "    Shared keys automatically flow between parent and subgraphs.\n",
    "    \"\"\"\n",
    "\n",
    "    customer_id: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e40da1",
   "metadata": {},
   "source": [
    "### Define Graph Nodes\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"../../images/verification_layer.png\" width=\"800\">\n",
    "</div>\n",
    "\n",
    "We'll create 4 nodes:\n",
    "1. **query_router**: Classifies whether a query needs identity verification before answering\n",
    "2. **verify_customer**: Ensures the agent has a valid `customer_id` based on provided email address\n",
    "3. **collect_email**: Dedicated HITL node that pauses with `interrupt()` to collect user input\n",
    "4. **supervisor_agent (subgraph)**: The supervisor agent that handles the actual query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae2ef91",
   "metadata": {},
   "source": [
    "#### Node 1: Query Router\n",
    "\n",
    "The \"Query Router\" node makes a decision about whether identity verification is required to answer the user's question.\n",
    "\n",
    "It inspects the agent's state and the user's latest message to determine:\n",
    "1. If the customer should be prompted for verification (such as when asking for information about a particular order), or \n",
    "2. If the request can proceed directly to the supervisor agent (for general questions or public information)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a305fcc",
   "metadata": {},
   "source": [
    "\n",
    "##### Helper Function\n",
    "\n",
    "We'll use an LLM with structured output to classify each user message to determine if it requires verification, so lets set that up first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1fe046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from langchain.chat_models import init_chat_model\n",
    "from config import DEFAULT_MODEL\n",
    "\n",
    "\n",
    "# TypedDict for structured LLM output\n",
    "class QueryClassification(TypedDict):\n",
    "    \"\"\"Classification of whether customer identity verification is required.\"\"\"\n",
    "\n",
    "    reasoning: Annotated[\n",
    "        str, ..., \"Brief explanation of why verification is or isn't needed\"\n",
    "    ]\n",
    "    requires_verification: Annotated[\n",
    "        bool,\n",
    "        ...,\n",
    "        \"True if the query requires knowing customer identity (e.g., 'my orders', 'my account', 'my purchases'). False for general questions (product info, policies, how-to questions).\",\n",
    "    ]\n",
    "\n",
    "\n",
    "def classify_query_intent(query: str) -> QueryClassification:\n",
    "    \"\"\"Classify whether a query requires customer identity verification.\n",
    "\n",
    "    Args:\n",
    "        query: The user's query string\n",
    "\n",
    "    Returns:\n",
    "        QueryClassification dict with reasoning and requires_verification fields\n",
    "    \"\"\"\n",
    "    llm = init_chat_model(DEFAULT_MODEL)\n",
    "\n",
    "    # Create structured LLM\n",
    "    structured_llm = llm.with_structured_output(QueryClassification)\n",
    "    classification_prompt = \"\"\"Analyze the user's query to determine if it requires knowing their customer identity in order to answer the question.\"\"\"\n",
    "\n",
    "    # Get structured classification\n",
    "    classification = structured_llm.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": classification_prompt},\n",
    "            {\"role\": \"user\", \"content\": \"Query: \" + query},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965328a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = classify_query_intent(\"Whats the status of my recent order?\")\n",
    "pprint.pprint(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a94b93",
   "metadata": {},
   "source": [
    "##### Node Implementation\n",
    "\n",
    "Now, we can leverage this `classify_query_intent` function in a node to intelligently decide when to route users for identity verification vs. letting them skip directly to the supervisor agent for general questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a09e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "# Node 1: Query Router\n",
    "def query_router(\n",
    "    state: IntermediateState,\n",
    ") -> Command[Literal[\"verify_customer\", \"supervisor_agent\"]]:\n",
    "    \"\"\"Route query based on verification needs.\n",
    "\n",
    "    Logic:\n",
    "    1. If customer already verified from earlier in the thread → supervisor_agent\n",
    "    2. If query needs verification → verify_customer\n",
    "    3. Otherwise → supervisor_agent\n",
    "    \"\"\"\n",
    "\n",
    "    # Already verified? Skip to supervisor agent\n",
    "    if state.get(\"customer_id\"):\n",
    "        return Command(goto=\"supervisor_agent\")\n",
    "\n",
    "    # Not already verified - classify query to see if verification is needed\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    query_classification = classify_query_intent(last_message.content)\n",
    "\n",
    "    # Route based on classification\n",
    "    if query_classification.get(\"requires_verification\"):\n",
    "        return Command(goto=\"verify_customer\")\n",
    "    return Command(goto=\"supervisor_agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c341204",
   "metadata": {},
   "source": [
    "#### Node 2: Verify Customer\n",
    "\n",
    "The \"Verify Customer\" node is responsible for ensuring our agent has a valid `customer_id` for the user. \n",
    "\n",
    "It does this by asking the customer to provide their email address, extracting it from their response, and then validating it against our TechHub database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d102cba",
   "metadata": {},
   "source": [
    "##### Helper Functions\n",
    "\n",
    "**1. Email Extraction**\n",
    "\n",
    "The first helper extracts email addresses from natural language user input. \n",
    "\n",
    "This uses structured output to parse messages like \"Ok cool, my email is bob@gmail.com\" into a clean format (i.e. \"bob@gmail.com\") that we can easily validate - we can't assume the user will respond with just a nicely formatted email address.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07509e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict, Annotated\n",
    "\n",
    "\n",
    "class EmailExtraction(TypedDict):\n",
    "    \"\"\"Schema for extracting email from user message.\"\"\"\n",
    "\n",
    "    email: Annotated[\n",
    "        str,\n",
    "        \"The email address extracted from the message, or empty string if none found\",\n",
    "    ]\n",
    "\n",
    "\n",
    "def create_email_extractor():\n",
    "    \"\"\"Create an LLM configured to extract emails from natural language.\"\"\"\n",
    "    llm = init_chat_model(DEFAULT_MODEL)\n",
    "    return llm.with_structured_output(EmailExtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c51cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test email extraction\n",
    "extractor = create_email_extractor()\n",
    "result = extractor.invoke(\"Ok cool, my email is bob@gmail.com\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2614ff06",
   "metadata": {},
   "source": [
    "**2. Customer Validation**\n",
    "\n",
    "The second helper validates an email address by referencing information in our TechHub database. It returns a `CustomerInfo` object with the `customer_id` and `customer_name` if the email exists, or `None` if not found.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "\n",
    "class CustomerInfo(NamedTuple):\n",
    "    \"\"\"Customer information returned from validation.\"\"\"\n",
    "\n",
    "    customer_id: str\n",
    "    customer_name: str\n",
    "\n",
    "\n",
    "def validate_customer_email(email: str, db: SQLDatabase) -> CustomerInfo | None:\n",
    "    \"\"\"Validate email format and lookup customer in database.\n",
    "\n",
    "    Args:\n",
    "        email: Email address to validate\n",
    "        db: SQLDatabase connection\n",
    "\n",
    "    Returns:\n",
    "        CustomerInfo with customer_id and customer_name if valid, None otherwise\n",
    "    \"\"\"\n",
    "    # Check email format\n",
    "    if not email or \"@\" not in email:\n",
    "        return None\n",
    "\n",
    "    # Lookup in database\n",
    "    result = db._execute(\n",
    "        f\"SELECT customer_id, name FROM customers WHERE email = '{email}'\"\n",
    "    )\n",
    "\n",
    "    # Convert SQLDatabase query results to list of tuples (values only)\n",
    "    result = [tuple(row.values()) for row in result]\n",
    "\n",
    "    if not result:\n",
    "        return None\n",
    "\n",
    "    customer_id, customer_name = result[0]\n",
    "    return CustomerInfo(customer_id=customer_id, customer_name=customer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381dc22e",
   "metadata": {},
   "source": [
    "Lets test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc900c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.database import get_database\n",
    "\n",
    "# Get database connection (lazy loaded)\n",
    "db = get_database()\n",
    "\n",
    "# Test customer validation - Valid email\n",
    "valid_customer = validate_customer_email(email=\"sarah.chen@gmail.com\", db=db)\n",
    "print(\"Valid email:\", valid_customer)\n",
    "\n",
    "# Test customer validation - Invalid email\n",
    "invalid_customer = validate_customer_email(email=\"nonexistent@example.com\", db=db)\n",
    "print(\"Invalid email:\", invalid_customer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a73fae",
   "metadata": {},
   "source": [
    "#### Node Implementation\n",
    "\n",
    "Now we can utilize these functions to build our `verify_customer` node, which has one job: **ensure we have a valid email and corresponding customer_id**.\n",
    "\n",
    "**Three-path logic:**\n",
    "\n",
    "1. **Try to extract email** from user's last message using structured output\n",
    "2. **If email found** → Validate against database:\n",
    "   - ✅ **Valid**: Set `customer_id` + `goto=\"supervisor_agent\"` (done!)\n",
    "   - ❌ **Invalid**: Return error + `goto=\"collect_email\"` (retry)\n",
    "3. **If no email found in message** → Request email + `goto=\"collect_email\"` (first time)\n",
    "\n",
    "**Why this design?**\n",
    "- **First visit** (from `query_router`): No email yet → Path 3 → Asks for it\n",
    "- **Subsequent visits** (from `collect_email`): Email present → Path 2 → Validates it\n",
    "\n",
    "One node handles both cases cleanly! Each path uses `Command(goto=...)` to explicitly control routing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8f7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "\n",
    "# Node 2: Verify Customer\n",
    "def verify_customer(\n",
    "    state: IntermediateState,\n",
    ") -> Command[Literal[\"supervisor_agent\", \"collect_email\"]]:\n",
    "    \"\"\"Ensure we have a valid customer email and set the `customer_id` in state.\n",
    "\n",
    "    Uses Command to explicitly route based on result.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get last message from user\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    # Try to extract email using structured output\n",
    "    email_extractor = create_email_extractor()\n",
    "    extraction = email_extractor.invoke([last_message])\n",
    "\n",
    "    # If we have an email, attempt to validate it\n",
    "    if extraction[\"email\"]:\n",
    "        db = get_database()\n",
    "        customer = validate_customer_email(email=extraction[\"email\"], db=db)\n",
    "\n",
    "        if customer:\n",
    "            # Success! Email verified → Go to supervisor\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"customer_id\": customer.customer_id,\n",
    "                    \"messages\": [\n",
    "                        AIMessage(\n",
    "                            content=f\"✓ Verified! Welcome back, {customer.customer_name}.\"\n",
    "                        )\n",
    "                    ],\n",
    "                },\n",
    "                goto=\"supervisor_agent\",\n",
    "            )\n",
    "        else:\n",
    "            # Email not valid → Try again\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"messages\": [\n",
    "                        AIMessage(\n",
    "                            content=f\"I couldn't find '{extraction['email']}' in our system. Please check and try again.\"\n",
    "                        )\n",
    "                    ]\n",
    "                },\n",
    "                goto=\"collect_email\",\n",
    "            )\n",
    "\n",
    "    # No email detected → Ask for it\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                AIMessage(\n",
    "                    content=\"To access information about your account or orders, please provide your email address.\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"collect_email\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5240a94b",
   "metadata": {},
   "source": [
    "#### Node 3: Collect Email (Human Input)\n",
    "\n",
    "The \"Collect Email\" node is our dedicated node for collecting the users input.\n",
    "\n",
    "By separating HITL into its own node, we get:\n",
    "- **Clear graph visualization** - The interrupt point is explicit in the graph\n",
    "- **Clean separation of concerns** - Business logic (verify_customer) separate from input collection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd61988",
   "metadata": {},
   "source": [
    "##### Node Implementation\n",
    "\n",
    "The node simply:\n",
    "1. Calls `interrupt()` to pause execution\n",
    "2. Waits for user to provide input via `Command(resume=...)`\n",
    "3. Updates state with the `HumanMessage` and routes back for verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e12fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import interrupt\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "# Node 3: Collect Email (HITL)\n",
    "def collect_email(state: IntermediateState) -> Command[Literal[\"verify_customer\"]]:\n",
    "    \"\"\"Dedicated node for collecting human input via interrupt.\"\"\"\n",
    "    user_input = interrupt(value=\"Please provide your email:\")\n",
    "    return Command(\n",
    "        update={\"messages\": [HumanMessage(content=user_input)]}, goto=\"verify_customer\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d63237",
   "metadata": {},
   "source": [
    "#### Node 4: Supervisor Agent\n",
    "\n",
    "The \"Supervisor Agent\" is the final node in our verification graph. It's a complete compiled graph from Section 3 that we're [reusing as a node](https://docs.langchain.com/oss/python/langgraph/use-subgraphs#add-a-graph-as-a-node)!\n",
    "\n",
    "> Note: We've refactored ALL agents from Section 3 (Database, Documents, and Supervisor) into the `agents/` directory as factory functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2e4b5f",
   "metadata": {},
   "source": [
    "##### Node Implementation\n",
    "\n",
    "We instantiate the supervisor agent using the factory function, which internally creates and wires together the sub-agents.\n",
    "\n",
    "**Key Implementation Detail:** We also pass `IntermediateState` to our supervisor agent. This creates a shared state schema between the verification graph and supervisor graph - all shared keys (`messages`, `customer_id`) automatically flow between.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac02200",
   "metadata": {},
   "source": [
    "**Introducing State-Dependent Agent Behavior with Dynamic Prompts**\n",
    "\n",
    "Up to this point (Sections 1-3), all agents operated without contextual state - they required explicit parameters in every query. But now that we have customer verification with `customer_id` stored in state, we can introduce **dynamic prompt injection** to make the supervisor agent context-aware!\n",
    "\n",
    "**The Pattern: Dynamic System Prompts**\n",
    "\n",
    "When a customer is verified, their `customer_id` is stored in the graph state. The supervisor agent uses the [`@dynamic_prompt` middleware](https://docs.langchain.com/oss/python/langchain/agents#dynamic-system-prompt) to automatically inject this information into its system prompt:\n",
    "\n",
    "```python\n",
    "@dynamic_prompt\n",
    "def supervisor_prompt(request: ModelRequest) -> str:\n",
    "    customer_id = request.state.get(\"customer_id\", None)\n",
    "    if customer_id:\n",
    "        return f\"\"\"{prompt}\n",
    "        \\n\\nThe customer's ID in this conversation is: {customer_id}\n",
    "        \"\"\"\n",
    "    return prompt\n",
    "```\n",
    "\n",
    "The supervisor can now coordinate queries with verified `customer_id` to the database specialist. See the full implementation in [`agents/supervisor_agent.py`](../../agents/supervisor_agent.py#L95-L104)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e81044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import create_db_agent, create_docs_agent, create_supervisor_agent\n",
    "from tools import get_customer_orders\n",
    "\n",
    "# Instantiate sub-agents - the db_agent now has access to get_customer_orders() which takes a customer_id\n",
    "db_agent = create_db_agent(additional_tools=[get_customer_orders])\n",
    "docs_agent = create_docs_agent()\n",
    "\n",
    "# Instantiate supervisor agent (which wraps the sub-agents as tools)\n",
    "supervisor_agent = create_supervisor_agent(\n",
    "    db_agent, docs_agent, state_schema=IntermediateState\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f97e1a",
   "metadata": {},
   "source": [
    "### Build and Compile the Verification Graph\n",
    "\n",
    "Now we wire everything together:\n",
    "- Add all nodes (including supervisor agent as a subgraph node)\n",
    "- Set entry point\n",
    "- Compile with checkpointer for persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7d4f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph, START\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Build the verification graph using MessagesState for input and output (i.e. just the messages key)\n",
    "# and IntermediateState (i.e. with customer_id key) for communication between nodes\n",
    "workflow = StateGraph(\n",
    "    input_schema=MessagesState,\n",
    "    state_schema=IntermediateState,\n",
    "    output_schema=MessagesState,\n",
    ")\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"query_router\", query_router)\n",
    "workflow.add_node(\"verify_customer\", verify_customer)\n",
    "workflow.add_node(\"collect_email\", collect_email)\n",
    "workflow.add_node(\"supervisor_agent\", supervisor_agent)\n",
    "\n",
    "# Set entry point\n",
    "workflow.add_edge(START, \"query_router\")\n",
    "\n",
    "# Compile with checkpointer (REQUIRED for interrupt)\n",
    "verification_graph = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad45906",
   "metadata": {},
   "source": [
    "### Visualize the Graph\n",
    "\n",
    "Let's see what we built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45983e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "display(Image(verification_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc0f1c3",
   "metadata": {},
   "source": [
    "## Test the Verification Graph\n",
    "\n",
    "Let's test all four scenarios:\n",
    "1. **General query** - No verification needed\n",
    "2. **Personal query** - Verification with successful email\n",
    "3. **Personal query with retry** - Invalid email, then valid email\n",
    "4. **Follow-up query** - Verification skipped (already verified in thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a9d06b",
   "metadata": {},
   "source": [
    "### Scenario 1: General Query (No HITL)\n",
    "\n",
    "Query about products or policies don't need customer identity verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0500da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "thread_id_1 = uuid.uuid4()\n",
    "config_1 = {\"configurable\": {\"thread_id\": thread_id_1}}\n",
    "\n",
    "result = verification_graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"how much does the Apple Magic Mouse cost?\")]},\n",
    "    config=config_1,\n",
    ")\n",
    "\n",
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6218909",
   "metadata": {},
   "source": [
    "### Scenario 2: Personal Query with Successful Verification\n",
    "\n",
    "Query about \"my orders\" require identity verification.\n",
    "\n",
    "**Test email:** `sarah.chen@gmail.com` (exists in database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e8702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New thread\n",
    "thread_id_2 = uuid.uuid4()\n",
    "config_2 = {\"configurable\": {\"thread_id\": thread_id_2}}\n",
    "\n",
    "# First invocation - will pause at interrupt\n",
    "result = verification_graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Whats the status of my recent order?\")]},\n",
    "    config=config_2,\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddecd381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume with valid email\n",
    "result = verification_graph.invoke(\n",
    "    Command(resume=\"Ok, its: sarah.chen@gmail.com\"),\n",
    "    config=config_2,\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9f9800",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a749c54",
   "metadata": {},
   "source": [
    "### Scenario 3: Personal Query with Retry (Invalid Email)\n",
    "\n",
    "What happens when the user provides an invalid email? The graph retries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c10d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New thread\n",
    "thread_id_3 = uuid.uuid4()\n",
    "config_3 = {\"configurable\": {\"thread_id\": thread_id_3}}\n",
    "\n",
    "\n",
    "# First invocation - pauses\n",
    "result = verification_graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Show me my recent purchases\")]},\n",
    "    config=config_3,\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1819d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume with INVALID email (not in database)\n",
    "result = verification_graph.invoke(Command(resume=\"wrong@email.com\"), config=config_3)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7456c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume with VALID email\n",
    "result = verification_graph.invoke(\n",
    "    Command(resume=\"Ah sorry its actually sarah.chen@gmail.com\"),\n",
    "    config=config_3,\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f831c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3d47cf",
   "metadata": {},
   "source": [
    "### Scenario 4: Follow-up Query (Skip Verification)\n",
    "\n",
    "Once verified in a thread, follow-up queries skip verification entirely!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c052920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same thread from Scenario 3 (already verified)\n",
    "\n",
    "result = verification_graph.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Can you remind me what was in ORD-2024-0081 and how much it cost?\"\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    config=config_3,  # Reuse config from Scenario 3\n",
    ")\n",
    "\n",
    "result[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
