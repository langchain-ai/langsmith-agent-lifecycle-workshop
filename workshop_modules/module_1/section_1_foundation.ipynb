{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1, Section 1: Foundational Concepts\n",
    "\n",
    "In this section, we'll build a simple customer support system for TechHub, a fictional e-commerce electronics store. \n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"../../images/db_agent.png\">\n",
    "</div>\n",
    "\n",
    "We'll start with the basics:\n",
    "1. How to make LLM calls with messages\n",
    "2. How to define tools that access external data (our TechHub database)\n",
    "3. The manual tool calling loop (involved but educational!)\n",
    "\n",
    "By the end, you'll understand **why** agent frameworks exist - spoiler, they automate the tedious parts we're about to implement manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's load our environment variables (API keys).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic LLM Call\n",
    "\n",
    "Let's start simple - just calling an LLM with a message.\n",
    "\n",
    "**Note:** The default model is set workshop-wide via WORKSHOP_MODEL in the .env file (see config.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from config import DEFAULT_MODEL\n",
    "\n",
    "print(f\"Using model: {DEFAULT_MODEL}\")\n",
    "\n",
    "# Initialize the model (using workshop default)\n",
    "llm = init_chat_model(DEFAULT_MODEL)\n",
    "\n",
    "# Simple string input\n",
    "response = llm.invoke(\"What is LangChain in under 10 words?\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Working with Messages\n",
    "\n",
    "LLMs work with **messages** that have roles:\n",
    "- `SystemMessage`: Instructions for how the LLM should behave\n",
    "- `HumanMessage`: User input\n",
    "- `AIMessage`: Model responses\n",
    "- `ToolMessage`: Results from tool execution (we'll see this soon!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Multi-turn conversation with messages\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful customer support assistant for TechHub, an electronics store.\"\n",
    "    ),\n",
    "    HumanMessage(content=\"Hello!\"),\n",
    "    AIMessage(content=\"Hi! How can I help you today?\"),\n",
    "    HumanMessage(content=\"What's the status of order ORD-2024-0123?\"),\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice the problem:** The LLM can't actually look up the order! It doesn't have access to our database.\n",
    "\n",
    "This is where **tools** come in.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining Tools\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"../../images/db_tools.png\">\n",
    "</div>\n",
    "\n",
    "Tools give LLMs the ability to interact with external systems. Let's create four tools that query our [TechHub database](../../data/structured/techhub_schema.png).\n",
    "\n",
    "The `@tool` decorator from `langchain` automatically:\n",
    "- Extracts the function signature for the LLM\n",
    "- Uses the docstring as the tool description\n",
    "- Handles the input/output formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from langchain.tools import tool\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# instaniate the database connection\n",
    "DB_PATH = Path(\"../../data/structured/techhub.db\")\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{DB_PATH}\")\n",
    "\n",
    "\n",
    "# helper function\n",
    "def extract_values(result):\n",
    "    \"\"\"Convert SQLDatabase query results (list of dicts) to list of tuples (values only).\"\"\"\n",
    "    return [tuple(row.values()) for row in result]\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_order_status(order_id: str) -> str:\n",
    "    \"\"\"Get status, dates, and tracking information for a specific order.\n",
    "\n",
    "    Note: For order total, calculate from items using get_order_item_price().\n",
    "\n",
    "    Args:\n",
    "        order_id: The order ID (e.g., \"ORD-2024-0123\")\n",
    "\n",
    "    Returns:\n",
    "        Formatted string with order status, dates, and tracking number.\n",
    "    \"\"\"\n",
    "    result = db._execute(\n",
    "        f\"\"\"\n",
    "        SELECT order_id, order_date, status, shipped_date, tracking_number\n",
    "        FROM orders\n",
    "        WHERE order_id = '{order_id}'\n",
    "    \"\"\"\n",
    "    )\n",
    "    result = extract_values(result)\n",
    "\n",
    "    if not result:\n",
    "        return f\"Order {order_id} not found.\"\n",
    "\n",
    "    order_id, order_date, status, shipped_date, tracking_number = result[0]\n",
    "\n",
    "    response = f\"Order {order_id}:\\n\"\n",
    "    response += f\"- Status: {status}\\n\"\n",
    "    response += f\"- Order Date: {order_date}\\n\"\n",
    "\n",
    "    if shipped_date:\n",
    "        response += f\"- Shipped Date: {shipped_date}\\n\"\n",
    "    if tracking_number:\n",
    "        response += f\"- Tracking Number: {tracking_number}\\n\"\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_order_items(order_id: str) -> str:\n",
    "    \"\"\"Get list of items in a specific order with product IDs and quantities.\n",
    "\n",
    "    Note: For pricing, use get_order_item_price() for historical price paid, or get_product_info() for current price.\n",
    "\n",
    "    Args:\n",
    "        order_id: The order ID (e.g., \"ORD-2024-0123\")\n",
    "\n",
    "    Returns:\n",
    "        Formatted string with product IDs and quantities (no prices).\n",
    "    \"\"\"\n",
    "    result = db._execute(\n",
    "        f\"\"\"\n",
    "        SELECT product_id, quantity\n",
    "        FROM order_items\n",
    "        WHERE order_id = '{order_id}'\n",
    "    \"\"\"\n",
    "    )\n",
    "    result = extract_values(result)\n",
    "\n",
    "    if not result:\n",
    "        return f\"No items found for order {order_id}.\"\n",
    "\n",
    "    response = f\"Items in order {order_id}:\\n\"\n",
    "    for product_id, quantity in result:\n",
    "        response += f\"- Product ID: {product_id}, Quantity: {quantity}\\n\"\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_product_info(product_identifier: str) -> str:\n",
    "    \"\"\"Get product details by product name or product ID.\n",
    "\n",
    "    Args:\n",
    "        product_identifier: Product name (e.g., \"MacBook Air\") or product ID (e.g., \"TECH-LAP-001\")\n",
    "\n",
    "    Returns:\n",
    "        Formatted string with product name, category, price, and stock status.\n",
    "    \"\"\"\n",
    "    # Try exact ID match first\n",
    "    result = db._execute(\n",
    "        f\"\"\"\n",
    "        SELECT product_id, name, category, price, in_stock\n",
    "        FROM products\n",
    "        WHERE product_id = '{product_identifier}'\n",
    "    \"\"\"\n",
    "    )\n",
    "    result = extract_values(result)\n",
    "\n",
    "    # If no exact match, try fuzzy name search\n",
    "    if not result:\n",
    "        result = db._execute(\n",
    "            f\"\"\"\n",
    "            SELECT product_id, name, category, price, in_stock\n",
    "            FROM products\n",
    "            WHERE name LIKE '%{product_identifier}%'\n",
    "            LIMIT 1\n",
    "        \"\"\"\n",
    "        )\n",
    "        result = extract_values(result)\n",
    "\n",
    "    if not result:\n",
    "        return f\"Product '{product_identifier}' not found.\"\n",
    "\n",
    "    product_id, name, category, price, in_stock = result[0]\n",
    "    stock_status = \"In Stock\" if in_stock else \"Out of Stock\"\n",
    "\n",
    "    return f\"{name} ({product_id})\\n- Category: {category}\\n- Price: ${price:.2f}\\n- Status: {stock_status}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_order_item_price(order_id: str, product_id: str) -> str:\n",
    "    \"\"\"Get the historical price paid for a specific item in an order.\n",
    "\n",
    "    Use this to get the actual price the customer paid at time of purchase,\n",
    "    which may differ from the current retail price from get_product_info().\n",
    "\n",
    "    Args:\n",
    "        order_id: The order ID (e.g., \"ORD-2024-0123\")\n",
    "        product_id: The product ID (e.g., \"TECH-LAP-001\")\n",
    "\n",
    "    Returns:\n",
    "        Formatted string with historical price per unit.\n",
    "    \"\"\"\n",
    "    result = db._execute(\n",
    "        f\"\"\"\n",
    "        SELECT price_per_unit, quantity\n",
    "        FROM order_items\n",
    "        WHERE order_id = '{order_id}' AND product_id = '{product_id}'\n",
    "        \"\"\"\n",
    "    )\n",
    "    result = extract_values(result)\n",
    "\n",
    "    if not result:\n",
    "        return f\"Item {product_id} not found in order {order_id}.\"\n",
    "\n",
    "    price, quantity = result[0]\n",
    "    return f\"Historical price for {product_id} in {order_id}: ${price:.2f} per unit (quantity: {quantity})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out the `get_order_status` tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_order = \"ORD-2024-0127\"\n",
    "result = get_order_status.invoke(example_order)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect how the `@tool` decorator parses the tool information into a `StructuredTool` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- TOOL NAME ---\")\n",
    "print(get_order_status.name)\n",
    "\n",
    "print(\"\\n--- TOOL DESCRIPTION ---\")\n",
    "print(get_order_status.description)\n",
    "\n",
    "print(\"\\n--- TOOL ARGUMENTS ---\")\n",
    "print(get_order_status.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_order_status.tool_call_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Manual Tool Calling Loop\n",
    "\n",
    "Now let's see how LLMs actually [use tools](https://docs.langchain.com/oss/python/langchain/models#tool-calling)! This happens in stages:\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"../../images/function-calling.png\">\n",
    "    <br>\n",
    "    <sub>\n",
    "        Image Source: <a href=\"https://www.philschmid.de/gemini-function-calling\">Phil Schmid Blog</a>\n",
    "    </sub>\n",
    "</div>\n",
    "\n",
    "Let's see each stage in action!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Bind tools to the model\n",
    "\n",
    "First, we tell the LLM what tools are available by \"binding\" them. This ensures that the available tool definitions are included with the model request.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind tools to the model - this tells the LLM what tools are available\n",
    "tools = [get_order_status, get_order_items, get_product_info, get_order_item_price]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps 1, 2, 3: Call the LLM with query, it decides to call a tool, and returns the formated tool call object\n",
    "\n",
    "Now let's give the LLM a query. It will decide which tool to call based on the available tool descriptions and respond with a tool call object including tool arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about an order\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful customer support assistant.\"),\n",
    "    HumanMessage(content=\"What's the status of order ORD-2024-0123?\"),\n",
    "]\n",
    "\n",
    "# Call the LLM\n",
    "response = llm_with_tools.invoke(messages)\n",
    "response.pretty_print()\n",
    "\n",
    "# Add the AI's tool call to messages\n",
    "messages.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Manually execute the tool\n",
    "\n",
    "The LLM told us _what_ to call and _with what arguments_. Now **we** need to actually execute the tool with the specified arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the tool call information\n",
    "tool_call = response.tool_calls[0]\n",
    "tool_name = tool_call[\"name\"]\n",
    "tool_args = tool_call[\"args\"]\n",
    "tool_call_id = tool_call[\"id\"]\n",
    "\n",
    "print(f\"[Executing]\\n Tool: {tool_name}\\n Args: {tool_args}\\n ID: {tool_call_id}\", \"\\n\")\n",
    "\n",
    "# Manually execute the tool\n",
    "if tool_name == \"get_order_status\":\n",
    "    tool_result = get_order_status.invoke(tool_args)\n",
    "elif tool_name == \"get_order_items\":\n",
    "    tool_result = get_order_items.invoke(tool_args)\n",
    "elif tool_name == \"get_product_info\":\n",
    "    tool_result = get_product_info.invoke(tool_args)\n",
    "elif tool_name == \"get_order_item_price\":\n",
    "    tool_result = get_order_item_price.invoke(tool_args)\n",
    "\n",
    "print(f\"[Tool Result]\\n {tool_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Pass results back to the LLM\n",
    "\n",
    "Now we need to send the tool result back to the LLM so it can generate a final answer for the user in natural language. Note that we use a `ToolMessage` type when adding tool result details back to the message history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# Create a ToolMessage with the result\n",
    "tool_message = ToolMessage(\n",
    "    content=tool_result,\n",
    "    tool_call_id=tool_call[\"id\"],  # Must match the ID from the tool call\n",
    ")\n",
    "messages.append(tool_message)\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Get the Final Answer\n",
    "\n",
    "Now the LLM has the tool result and can give a complete answer in natural language to the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the LLM again with the tool result\n",
    "final_response = llm_with_tools.invoke(messages)\n",
    "\n",
    "final_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting It All Together: The Loop\n",
    "\n",
    "In real scenarios, the LLM might need to call multiple tools or loop several times. Let's create a function that automates this process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent_loop(user_query: str):\n",
    "    \"\"\"Run the complete tool calling loop.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful customer support assistant for TechHub.\"\n",
    "        ),\n",
    "        HumanMessage(content=user_query),\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"User: {user_query}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # Keep looping until we get a final answer\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        iteration += 1\n",
    "\n",
    "        # Call the LLM\n",
    "        response = llm_with_tools.invoke(messages)\n",
    "\n",
    "        # Check if LLM wants to use tools\n",
    "        if not response.tool_calls:\n",
    "            # No tools needed - we have the final answer!\n",
    "            print(f\"[Final Answer]\\n {response.content}\\n\")\n",
    "            break\n",
    "\n",
    "        # LLM wants to use tools\n",
    "        print(\n",
    "            f\"[Iteration {iteration}] LLM is calling {len(response.tool_calls)} tool(s)...\"\n",
    "        )\n",
    "        messages.append(response)\n",
    "\n",
    "        # Execute each tool\n",
    "        for tool_call in response.tool_calls:\n",
    "            tool_name = tool_call[\"name\"]\n",
    "            tool_args = tool_call[\"args\"]\n",
    "\n",
    "            # Execute the tool\n",
    "            if tool_name == \"get_order_status\":\n",
    "                result = get_order_status.invoke(tool_args)\n",
    "            elif tool_name == \"get_order_items\":\n",
    "                result = get_order_items.invoke(tool_args)\n",
    "            elif tool_name == \"get_product_info\":\n",
    "                result = get_product_info.invoke(tool_args)\n",
    "            elif tool_name == \"get_order_item_price\":\n",
    "                result = get_order_item_price.invoke(tool_args)\n",
    "\n",
    "            arg_str = \", \".join(f\"{k}={v!r}\" for k, v in tool_args.items())\n",
    "            print(f\"  â†’ {tool_name}({arg_str})\")\n",
    "\n",
    "            # Add tool result to messages\n",
    "            messages.append(\n",
    "                ToolMessage(content=str(result), tool_call_id=tool_call[\"id\"])\n",
    "            )\n",
    "\n",
    "        print()  # Blank line before next iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try It Out!\n",
    "\n",
    "Now let's test our agent loop with different queries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1: Simple order lookup**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_agent_loop(\"What's the status of order ORD-2024-0123?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2: Product price lookup**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_agent_loop(\"How much does the MacBook Air cost?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 3: Multiple tools in one query**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_agent_loop(\n",
    "    \"What's the status of order ORD-2024-0123, what was in it, and how much did it cost?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
